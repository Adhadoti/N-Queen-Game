{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "700fa271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/ankurdhadoti/opt/anaconda3/lib/python3.8/site-packages (2.25.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ankurdhadoti/opt/anaconda3/lib/python3.8/site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ankurdhadoti/opt/anaconda3/lib/python3.8/site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/ankurdhadoti/opt/anaconda3/lib/python3.8/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/ankurdhadoti/opt/anaconda3/lib/python3.8/site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/ankurdhadoti/opt/anaconda3/lib/python3.8/site-packages (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/ankurdhadoti/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4) (2.2.1)\n",
      "Requirement already satisfied: html-table-parser-python3 in /Users/ankurdhadoti/opt/anaconda3/lib/python3.8/site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install requests\n",
    "! pip3 install beautifulsoup4\n",
    "!pip install html-table-parser-python3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6954a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li class=\"header-link\"><a href=\"/home\">Home</a></li>\n",
      "<li class=\"header-link\"><a href=\"/about\">About</a></li>\n",
      "<li class=\"header-link\"><a href=\"/research\">Research</a></li>\n",
      "<li>11111</li>\n",
      "<li>12</li>\n",
      "<li>22</li>\n",
      "<li>1121</li>\n",
      "<li>22121</li>\n",
      "<li>11222</li>\n",
      "<li>2111</li>\n",
      "<li>111</li>\n",
      "<li>122</li>\n",
      "<li>2111</li>\n",
      "<li>22</li>\n",
      "<li>111212</li>\n",
      "<li>21</li>\n",
      "<li>21111</li>\n",
      "<li>121222</li>\n",
      "<li>111</li>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6d4b628c58f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-6d4b628c58f4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0murl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#def math()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    " \n",
    "url = 'http://cse2050.drfitz.fit/armstrong/base3.html'\n",
    "reqs = requests.get(url)\n",
    "soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "\n",
    "for link in soup.find_all('li'):\n",
    "\n",
    "        print(link)\n",
    "    \n",
    "def main():\n",
    "    page='base'\n",
    "    html='.html'\n",
    "    for i in range(3,11):\n",
    "        word=page+str(i)+html\n",
    "        url(word)\n",
    "    \n",
    "#def math()\n",
    "#def filter()\n",
    "    \n",
    "    \n",
    "main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def url(word):\n",
    "    url = 'http://cse2050.drfitz.fit/armstrong/word.html'\n",
    "    reqs = requests.get(url)\n",
    "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "\n",
    "    for link in soup.find_all('li'):\n",
    "        print(link)\n",
    "    \n",
    "url()\n",
    "\n",
    "\n",
    "def math():\n",
    "    value=122\n",
    "    value=[int(x) for x in str(value)]\n",
    "    add=0\n",
    "    power=3\n",
    "    base=3\n",
    "    calculation=0\n",
    "    loop=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(0,len(value)):\n",
    "        \n",
    "        add+=value[i]**power\n",
    "        calculation+=value[i]*(base**(len(value)-loop))\n",
    "        loop+=1\n",
    "        \n",
    "        \n",
    "    if add==calculation:\n",
    "        print(\"pass\")\n",
    "        print(calculation)\n",
    "        \n",
    "    else:\n",
    "        print(\"fail\")\n",
    "        \n",
    "math()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2984823a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully opened the web page\n",
      "The news are as follow :-\n",
      "\n",
      "<div class=\"section\">\n",
      "<h2>Armstrong in the Rough</h2>\n",
      "<p>\n",
      " \t \tA number N is an <i>Armstrong number of order n</i> (<i>n</i> being the number of digits) if\n",
      "\t\tabcd ... = a<sup>n</sup> +b<sup>n</sup> +c<sup>n</sup> +d<sup>n</sup> + ... = N. <br/>\n",
      "\t\tThe number 153 is an Armstrong number of order 3 because\n",
      "\t\t1<sup>3</sup> + 5<sup>3</sup> + 3<sup>3</sup> = 1 + 125 + 27 = 153.\n",
      "\t</p>\n",
      "<p>\n",
      "\t\tLikewise, 54748 is an Armstrong number of order 5 because\n",
      "\t\t5<sup>5</sup> + 4<sup>5</sup> + 7<sup>5</sup> + 4<sup>5</sup> + 8<sup>5</sup> = 3125 + 1024 + 16807 + 1024 + 32768 = 54748.\n",
      "\t</p>\n",
      "<p>\n",
      "\t\tMore generally, an n-digit number in base <i>b</i> is said to be a base <i>b</i> Armstrong number of order <i>n</i> if it equals the sum of the n<sup>th</sup> powers of its base <i>b</i> digits. \n",
      "\t</p>\n",
      "<p>\n",
      "\t\t122 in Armstrong form is 1<sup>3</sup>+ 2<sup>3</sup> + 2<sup>3</sup> = 17<br/>\n",
      "\t\t122 base 3 is equivalent to 2*1 + 2*3 + 1*9 = 17\n",
      "\t</p>\n",
      "<p class=\"highlighted_text\">\n",
      "\t\t\n",
      "\t\tThe following list contains base 3-10 Armstrong numbers in the rough like diamonds. This means there are some impersonators included who are acting like Armstrong numbers when they are not.  They are not really narcissistic. Can you find the real base <i>b</i> armstrong numbers in the list? \n",
      "\t</p>\n",
      "<p>\n",
      "\t\tDid you know that Armstrong numbers are very narcissistic? <a href=\"https://www.britannica.com/science/narcissistic-number\" target=\"_blank\">Click here</a> to read more.\n",
      " \t </p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "  \n",
    "def news():\n",
    "    # the target we want to open    \n",
    "    url='http://cse2050.drfitz.fit/armstrong/'\n",
    "      \n",
    "    #open with GET method\n",
    "    resp=requests.get(url)\n",
    "      \n",
    "    #http_respone 200 means OK status\n",
    "    if resp.status_code==200:\n",
    "        print(\"Successfully opened the web page\")\n",
    "        print(\"The news are as follow :-\\n\")\n",
    "    \n",
    "        soup=BeautifulSoup(resp.text,'html.parser')    \n",
    "  \n",
    "        # l is the list which contains all the text i.e news \n",
    "        l=soup.find(\"div\",{\"class\":\"section\"})\n",
    "        print(l)\n",
    "\n",
    "\n",
    "      \n",
    "        #now we want to print only the text part of the anchor.\n",
    "        #find all the elements of a, i.e anchor\n",
    "        #for i in l.findAll(\"href\"):\n",
    "            #print(i.text)\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "          \n",
    "news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fafd6994",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-5-cec435665d37>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-cec435665d37>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for link in soup.findAll('a'):\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "html_page = urllib2.urlopen(\"http://cse2050.drfitz.fit/armstrong/\")\n",
    "soup = BeautifulSoup(html_page)\n",
    "for link in soup.findAll('a'):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "213dee66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li class=\"header-link\"><a href=\"/home\">Home</a></li>\n",
      "<li class=\"header-link\"><a href=\"/about\">About</a></li>\n",
      "<li class=\"header-link\"><a href=\"/research\">Research</a></li>\n",
      "<li><a href=\"base3.html\">Base 3 armstrong numbers</a></li>\n",
      "<li><a href=\"base4.html\">Base 4 armstrong numbers</a></li>\n",
      "<li><a href=\"base5.html\">Base 5 armstrong numbers</a></li>\n",
      "<li><a href=\"base6.html\">Base 6 armstrong numbers</a></li>\n",
      "<li><a href=\"base7.html\">Base 7 armstrong numbers</a></li>\n",
      "<li><a href=\"base8.html\">Base 8 armstrong numbers</a></li>\n",
      "<li><a href=\"base9.html\">Base 9 armstrong numbers</a></li>\n",
      "<li><a href=\"base10.html\">Base 10 armstrong numbers</a></li>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    " \n",
    "url = 'http://cse2050.drfitz.fit/armstrong/'\n",
    "reqs = requests.get(url)\n",
    "soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "\n",
    "for link in soup.find_all('li'):\n",
    "    find_all_a = soup.find_all(href=True)\n",
    "    print(link)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f74a24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base3.html\n",
      "base4.html\n",
      "base5.html\n",
      "base6.html\n",
      "base7.html\n",
      "base8.html\n",
      "base9.html\n",
      "base10.html\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    page='base'\n",
    "    html='.html'\n",
    "    for i in range(3,11):\n",
    "        word=page+str(i)+html\n",
    "        print(word)\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8743534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "\n",
    "data_table =[]\n",
    "\n",
    "def get_html(url):\n",
    "    response = requests.get(url)  # get page data from server, block redirects\n",
    "    source_code = response.content  # get string of source code from response\n",
    "    return source_code\n",
    "\n",
    "\n",
    "def scrape_data(url):\n",
    "    return get_data_table(get_html(url))\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    url = \"https://www.britannica.com/topic/list-of-state-capitals-in-the-United- States-2119210\"\n",
    "    data_table = scrape_data(url)\n",
    "    print(data_table)\n",
    "# Call the main function to begin executing the program.\n",
    "main()\n",
    "        \n",
    "\n",
    "def get_data_table(source_code):\n",
    "    \n",
    "    data_table = []\n",
    "    html_elem = html.document_fromstring(source_code) # make HTML element object tables = html_elem.cssselect(\"table\")\n",
    "    \n",
    "    \n",
    "    for tr in trs:\n",
    "        output_table_row = []\n",
    "        tds = tr.cssselect('td')  # a td is a HTML table cell; selecting td selects a group of cells\n",
    "                 # go through each cell and grab the text content\n",
    "        for td in tds:\n",
    "            cell_text = td.text_content().strip()\n",
    "            output_table_row.append(cell_text)\n",
    "            data_table.append(output_table_row)\n",
    "    return data_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6048f861-8931-4561-94bc-bd364be382e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'urllib' is not defined\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import bs4 # from bs4 import BeautifulSoup import urllib.request\n",
    "def main() :\n",
    "    url = 'http://cse2050.drfitz.fit/armstrong/'\n",
    "    visited = []\n",
    "    crawl(url, 20, visited)\n",
    "    print(visited)\n",
    "\n",
    "\n",
    "def crawl(address, depth, visited) : \n",
    "    if depth == 0 :\n",
    "        return \n",
    "    try :\n",
    "        response = urllib.request.urlopen(address) \n",
    "        doc = bs4.BeautifulSoup(response) \n",
    "        print(\"Visiting \" + address)\n",
    "        for link in doc.find_all(\"a\") :\n",
    "            href = link[\"href\"]\n",
    "            if href[0:4] == \"http\" and href not in visited :\n",
    "                visited.append(href)\n",
    "                crawl(href, depth - 1, visited) \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398c67d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
